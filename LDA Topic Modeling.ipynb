{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling with gensim and spacy\n",
    "\n",
    "LDA, or Latent Direchlet Allocation. https://en.wikipedia.org/wiki/Dirichlet_distribution\n",
    "In LDA modeling,\n",
    "\n",
    "- each document is a mixture of topics\n",
    "- each topic is a mixture of words or tokens.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Using Scikit to convert a corpus to a matrix of token counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('NLP_Data/pride_chp1.txt','r') as f1:\n",
    "    pride_corpus = f1.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 328)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(pride_corpus)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 224)\t1\n",
      "  (0, 17)\t1\n",
      "  (0, 226)\t1\n",
      "  (2, 25)\t1\n",
      "  (2, 138)\t1\n",
      "  (2, 37)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X_train_counts[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count TF-IDF\n",
    "\n",
    "Transform token counts into TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 328)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 17)\t0.5773502691896258\n",
      "  (0, 224)\t0.5773502691896258\n",
      "  (0, 226)\t0.5773502691896258\n",
      "  (2, 54)\t0.2773500981126146\n",
      "  (2, 80)\t0.2773500981126146\n",
      "  (2, 108)\t0.2773500981126146\n",
      "  (2, 135)\t0.2773500981126146\n",
      "  (2, 202)\t0.2773500981126146\n",
      "  (2, 227)\t0.2773500981126146\n",
      "  (2, 235)\t0.2773500981126146\n",
      "  (2, 263)\t0.2773500981126146\n",
      "  (2, 270)\t0.2773500981126146\n",
      "  (2, 271)\t0.5547001962252291\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tf[0:35:7]) # we're just trying to show some random data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=1000,\n",
    "                                stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = tf_vectorizer.fit_transform(pride_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['However little known the feelings or views of such a man may be on his\\n',\n",
       " 'first entering a neighbourhood, this truth is so well fixed in the minds\\n',\n",
       " 'of the surrounding families, that he is considered the rightful property\\n',\n",
       " 'of some one or other of their daughters.\\n',\n",
       " '\\n',\n",
       " '\"My dear Mr. Bennet,\" said his lady to him one day, \"have you heard that\\n',\n",
       " 'Netherfield Park is let at last?\"\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pride_corpus[12:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top_words = 5\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: woman _her_ wife bingley know\n",
      "Topic #1: replied assure little want bennet\n",
      "Topic #2: man thinking little beauty daughters\n",
      "Topic #3: mr dear bennet jane better\n",
      "Topic #4: girls sure thing lizzy daughters\n",
      "Topic #5: visit nerves good lady young\n",
      "Topic #6: wife replied neighbourhood good _her_\n",
      "Topic #7: neighbourhood single netherfield thousand girls\n",
      "Topic #8: design years marrying know girls\n",
      "Topic #9: long possession man mrs know\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=10, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "lda.fit(tf)\n",
    "\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
